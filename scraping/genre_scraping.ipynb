{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MAIN_GENRE and Scraping\n",
    "We retrieve the genre information from the Rotten Tomatoes website since it is well-known and if frequently updated. Before scraping, we inspected the website using /robots.txt. We then proceeded scraping the information while complying with the instructions posted on the page.\n",
    "\n",
    "The code used to scrape can be found in web_crawler.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (4099625693.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[1], line 2\u001b[0;36m\u001b[0m\n\u001b[0;31m    pip install unidecode\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# pip install selenium\n",
    "pip install unidecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import SGDClassifier, LogisticRegression\n",
    "from sklearn.metrics import RocCurveDisplay, recall_score, precision_score, roc_curve, roc_auc_score, balanced_accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import for scrapping\n",
    "from unidecode import unidecode\n",
    "import web_crawler as wc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('grouped_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of na_genre initially:  (1865, 3)\n"
     ]
    }
   ],
   "source": [
    "na_genre = df[df['genre'].isna()]\n",
    "\n",
    "na_genre_cols = ['type', 'show_title','week']\n",
    "na_genre = na_genre[na_genre_cols]\n",
    "print(\"shape of na_genre initially: \", na_genre.shape)\n",
    "\n",
    "def mapping_category(string):\n",
    "  ''' \n",
    "  Method to find the category which will later be used in url parsing \n",
    "  '''\n",
    "  string = unidecode(string)\n",
    "\n",
    "  if(string==\"Films\"):\n",
    "    string = \"m\"\n",
    "  else:\n",
    "    string = \"tv\"\n",
    "  # print(string)\n",
    "  return string\n",
    "\n",
    "def mapping_title(name):\n",
    "  '''\n",
    "  Method to find the title name which will later be used in url parsing\n",
    "  '''\n",
    "  name = unidecode(name)\n",
    "  name = name.lower()\n",
    "  #removing all punctuation\n",
    "  # https://www.geeksforgeeks.org/python-remove-punctuation-from-string/\n",
    "  punctuation = '''!()-[]{};:'\"\\,<>./?@#$%^&*_~'''\n",
    "  for punctuation in punctuation:\n",
    "    name = name.replace(punctuation, '')\n",
    "  list = name.split()\n",
    "  return \"_\".join(list)\n",
    "\n",
    "def alt_mapping_category(string):\n",
    "  \"\"\"\n",
    "  Method to find the category which will later be used in url parsing just in case \n",
    "  given category was incorrectly listed \n",
    "  \"\"\"\n",
    "\n",
    "  #in case the type was incorrectly listed \n",
    "  string = unidecode(string)\n",
    "  if(string==\"m\"):\n",
    "    string = \"tv\"\n",
    "  else:\n",
    "    string = \"m\"\n",
    "  # print(string)\n",
    "  return string\n",
    "\n",
    "def mapping_year(week):\n",
    "  \"\"\"\n",
    "  Method to find the release year which will later be used in url parsing in the\n",
    "  case that shows have duplicate names \n",
    "  \"\"\"\n",
    "  return week[:4]\n",
    "\n",
    "na_genre['type'] = na_genre['type'].map(mapping_category)\n",
    "\n",
    "na_genre['show_title'] = na_genre['show_title'].map(mapping_title)\n",
    "\n",
    "na_genre['type2'] = na_genre['type'].map(alt_mapping_category)\n",
    "\n",
    "na_genre['year'] = na_genre['week'].map(mapping_year)\n",
    "\n",
    "na_genre[\"url\"] = \"https://www.rottentomatoes.com/\" + na_genre[\"type\"]+\"/\"+na_genre['show_title']+\"_\"+na_genre['year'] #first try\n",
    "\n",
    "na_genre[\"url2\"] = \"https://www.rottentomatoes.com/\" + na_genre[\"type\"]+\"/\"+na_genre['show_title'] #second try \n",
    "\n",
    "na_genre[\"url3\"] = \"https://www.rottentomatoes.com/\" + na_genre[\"type2\"]+\"/\"+na_genre['show_title']+\"_\"+na_genre['year'] #third try\n",
    "\n",
    "na_genre[\"url4\"] = \"https://www.rottentomatoes.com/\" + na_genre[\"type2\"]+\"/\"+na_genre['show_title'] #fourth try \n",
    "\n",
    "na_genre = na_genre.drop_duplicates(subset=['show_title'])\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# na_genre.to_csv(\"output_filename.csv\", index=False, encoding='utf8')\n",
    "\n",
    "# na_genre.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>show_title</th>\n",
       "      <th>week</th>\n",
       "      <th>type2</th>\n",
       "      <th>year</th>\n",
       "      <th>url</th>\n",
       "      <th>url2</th>\n",
       "      <th>url3</th>\n",
       "      <th>url4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>m</td>\n",
       "      <td>83</td>\n",
       "      <td>2022-04-03</td>\n",
       "      <td>tv</td>\n",
       "      <td>2022</td>\n",
       "      <td>https://www.rottentomatoes.com/m/83_2022</td>\n",
       "      <td>https://www.rottentomatoes.com/m/83</td>\n",
       "      <td>https://www.rottentomatoes.com/tv/83_2022</td>\n",
       "      <td>https://www.rottentomatoes.com/tv/83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>m</td>\n",
       "      <td>10_days_of_a_bad_man</td>\n",
       "      <td>2023-08-27</td>\n",
       "      <td>tv</td>\n",
       "      <td>2023</td>\n",
       "      <td>https://www.rottentomatoes.com/m/10_days_of_a_...</td>\n",
       "      <td>https://www.rottentomatoes.com/m/10_days_of_a_...</td>\n",
       "      <td>https://www.rottentomatoes.com/tv/10_days_of_a...</td>\n",
       "      <td>https://www.rottentomatoes.com/tv/10_days_of_a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>m</td>\n",
       "      <td>10_days_of_a_good_man</td>\n",
       "      <td>2023-03-12</td>\n",
       "      <td>tv</td>\n",
       "      <td>2023</td>\n",
       "      <td>https://www.rottentomatoes.com/m/10_days_of_a_...</td>\n",
       "      <td>https://www.rottentomatoes.com/m/10_days_of_a_...</td>\n",
       "      <td>https://www.rottentomatoes.com/tv/10_days_of_a...</td>\n",
       "      <td>https://www.rottentomatoes.com/tv/10_days_of_a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>m</td>\n",
       "      <td>1000_miles_from_christmas</td>\n",
       "      <td>2022-01-02</td>\n",
       "      <td>tv</td>\n",
       "      <td>2022</td>\n",
       "      <td>https://www.rottentomatoes.com/m/1000_miles_fr...</td>\n",
       "      <td>https://www.rottentomatoes.com/m/1000_miles_fr...</td>\n",
       "      <td>https://www.rottentomatoes.com/tv/1000_miles_f...</td>\n",
       "      <td>https://www.rottentomatoes.com/tv/1000_miles_f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>m</td>\n",
       "      <td>12_strong</td>\n",
       "      <td>2022-07-24</td>\n",
       "      <td>tv</td>\n",
       "      <td>2022</td>\n",
       "      <td>https://www.rottentomatoes.com/m/12_strong_2022</td>\n",
       "      <td>https://www.rottentomatoes.com/m/12_strong</td>\n",
       "      <td>https://www.rottentomatoes.com/tv/12_strong_2022</td>\n",
       "      <td>https://www.rottentomatoes.com/tv/12_strong</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1860</th>\n",
       "      <td>m</td>\n",
       "      <td>maboroshi</td>\n",
       "      <td>2024-01-21</td>\n",
       "      <td>tv</td>\n",
       "      <td>2024</td>\n",
       "      <td>https://www.rottentomatoes.com/m/maboroshi_2024</td>\n",
       "      <td>https://www.rottentomatoes.com/m/maboroshi</td>\n",
       "      <td>https://www.rottentomatoes.com/tv/maboroshi_2024</td>\n",
       "      <td>https://www.rottentomatoes.com/tv/maboroshi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1861</th>\n",
       "      <td>m</td>\n",
       "      <td>que_viva_mexico</td>\n",
       "      <td>2023-06-04</td>\n",
       "      <td>tv</td>\n",
       "      <td>2023</td>\n",
       "      <td>https://www.rottentomatoes.com/m/que_viva_mexi...</td>\n",
       "      <td>https://www.rottentomatoes.com/m/que_viva_mexico</td>\n",
       "      <td>https://www.rottentomatoes.com/tv/que_viva_mex...</td>\n",
       "      <td>https://www.rottentomatoes.com/tv/que_viva_mexico</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1862</th>\n",
       "      <td>m</td>\n",
       "      <td>ijogbon</td>\n",
       "      <td>2023-10-22</td>\n",
       "      <td>tv</td>\n",
       "      <td>2023</td>\n",
       "      <td>https://www.rottentomatoes.com/m/ijogbon_2023</td>\n",
       "      <td>https://www.rottentomatoes.com/m/ijogbon</td>\n",
       "      <td>https://www.rottentomatoes.com/tv/ijogbon_2023</td>\n",
       "      <td>https://www.rottentomatoes.com/tv/ijogbon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1863</th>\n",
       "      <td>m</td>\n",
       "      <td>shb_wl_`zw</td>\n",
       "      <td>2022-02-06</td>\n",
       "      <td>tv</td>\n",
       "      <td>2022</td>\n",
       "      <td>https://www.rottentomatoes.com/m/shb_wl_`zw_2022</td>\n",
       "      <td>https://www.rottentomatoes.com/m/shb_wl_`zw</td>\n",
       "      <td>https://www.rottentomatoes.com/tv/shb_wl_`zw_2022</td>\n",
       "      <td>https://www.rottentomatoes.com/tv/shb_wl_`zw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1864</th>\n",
       "      <td>m</td>\n",
       "      <td>bisangseoneon</td>\n",
       "      <td>2023-04-16</td>\n",
       "      <td>tv</td>\n",
       "      <td>2023</td>\n",
       "      <td>https://www.rottentomatoes.com/m/bisangseoneon...</td>\n",
       "      <td>https://www.rottentomatoes.com/m/bisangseoneon</td>\n",
       "      <td>https://www.rottentomatoes.com/tv/bisangseoneo...</td>\n",
       "      <td>https://www.rottentomatoes.com/tv/bisangseoneon</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1865 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     type                 show_title        week type2  year  \\\n",
       "0       m                         83  2022-04-03    tv  2022   \n",
       "1       m       10_days_of_a_bad_man  2023-08-27    tv  2023   \n",
       "2       m      10_days_of_a_good_man  2023-03-12    tv  2023   \n",
       "3       m  1000_miles_from_christmas  2022-01-02    tv  2022   \n",
       "4       m                  12_strong  2022-07-24    tv  2022   \n",
       "...   ...                        ...         ...   ...   ...   \n",
       "1860    m                  maboroshi  2024-01-21    tv  2024   \n",
       "1861    m            que_viva_mexico  2023-06-04    tv  2023   \n",
       "1862    m                    ijogbon  2023-10-22    tv  2023   \n",
       "1863    m                 shb_wl_`zw  2022-02-06    tv  2022   \n",
       "1864    m              bisangseoneon  2023-04-16    tv  2023   \n",
       "\n",
       "                                                    url  \\\n",
       "0              https://www.rottentomatoes.com/m/83_2022   \n",
       "1     https://www.rottentomatoes.com/m/10_days_of_a_...   \n",
       "2     https://www.rottentomatoes.com/m/10_days_of_a_...   \n",
       "3     https://www.rottentomatoes.com/m/1000_miles_fr...   \n",
       "4       https://www.rottentomatoes.com/m/12_strong_2022   \n",
       "...                                                 ...   \n",
       "1860    https://www.rottentomatoes.com/m/maboroshi_2024   \n",
       "1861  https://www.rottentomatoes.com/m/que_viva_mexi...   \n",
       "1862      https://www.rottentomatoes.com/m/ijogbon_2023   \n",
       "1863   https://www.rottentomatoes.com/m/shb_wl_`zw_2022   \n",
       "1864  https://www.rottentomatoes.com/m/bisangseoneon...   \n",
       "\n",
       "                                                   url2  \\\n",
       "0                   https://www.rottentomatoes.com/m/83   \n",
       "1     https://www.rottentomatoes.com/m/10_days_of_a_...   \n",
       "2     https://www.rottentomatoes.com/m/10_days_of_a_...   \n",
       "3     https://www.rottentomatoes.com/m/1000_miles_fr...   \n",
       "4            https://www.rottentomatoes.com/m/12_strong   \n",
       "...                                                 ...   \n",
       "1860         https://www.rottentomatoes.com/m/maboroshi   \n",
       "1861   https://www.rottentomatoes.com/m/que_viva_mexico   \n",
       "1862           https://www.rottentomatoes.com/m/ijogbon   \n",
       "1863        https://www.rottentomatoes.com/m/shb_wl_`zw   \n",
       "1864     https://www.rottentomatoes.com/m/bisangseoneon   \n",
       "\n",
       "                                                   url3  \\\n",
       "0             https://www.rottentomatoes.com/tv/83_2022   \n",
       "1     https://www.rottentomatoes.com/tv/10_days_of_a...   \n",
       "2     https://www.rottentomatoes.com/tv/10_days_of_a...   \n",
       "3     https://www.rottentomatoes.com/tv/1000_miles_f...   \n",
       "4      https://www.rottentomatoes.com/tv/12_strong_2022   \n",
       "...                                                 ...   \n",
       "1860   https://www.rottentomatoes.com/tv/maboroshi_2024   \n",
       "1861  https://www.rottentomatoes.com/tv/que_viva_mex...   \n",
       "1862     https://www.rottentomatoes.com/tv/ijogbon_2023   \n",
       "1863  https://www.rottentomatoes.com/tv/shb_wl_`zw_2022   \n",
       "1864  https://www.rottentomatoes.com/tv/bisangseoneo...   \n",
       "\n",
       "                                                   url4  \n",
       "0                  https://www.rottentomatoes.com/tv/83  \n",
       "1     https://www.rottentomatoes.com/tv/10_days_of_a...  \n",
       "2     https://www.rottentomatoes.com/tv/10_days_of_a...  \n",
       "3     https://www.rottentomatoes.com/tv/1000_miles_f...  \n",
       "4           https://www.rottentomatoes.com/tv/12_strong  \n",
       "...                                                 ...  \n",
       "1860        https://www.rottentomatoes.com/tv/maboroshi  \n",
       "1861  https://www.rottentomatoes.com/tv/que_viva_mexico  \n",
       "1862          https://www.rottentomatoes.com/tv/ijogbon  \n",
       "1863       https://www.rottentomatoes.com/tv/shb_wl_`zw  \n",
       "1864    https://www.rottentomatoes.com/tv/bisangseoneon  \n",
       "\n",
       "[1865 rows x 9 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "na_genre.reset_index(drop=True)\n",
    "# import web_crawler as wc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>url2</th>\n",
       "      <th>url3</th>\n",
       "      <th>url4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.rottentomatoes.com/m/83_2022</td>\n",
       "      <td>https://www.rottentomatoes.com/m/83</td>\n",
       "      <td>https://www.rottentomatoes.com/tv/83_2022</td>\n",
       "      <td>https://www.rottentomatoes.com/tv/83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.rottentomatoes.com/m/10_days_of_a_...</td>\n",
       "      <td>https://www.rottentomatoes.com/m/10_days_of_a_...</td>\n",
       "      <td>https://www.rottentomatoes.com/tv/10_days_of_a...</td>\n",
       "      <td>https://www.rottentomatoes.com/tv/10_days_of_a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.rottentomatoes.com/m/10_days_of_a_...</td>\n",
       "      <td>https://www.rottentomatoes.com/m/10_days_of_a_...</td>\n",
       "      <td>https://www.rottentomatoes.com/tv/10_days_of_a...</td>\n",
       "      <td>https://www.rottentomatoes.com/tv/10_days_of_a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.rottentomatoes.com/m/1000_miles_fr...</td>\n",
       "      <td>https://www.rottentomatoes.com/m/1000_miles_fr...</td>\n",
       "      <td>https://www.rottentomatoes.com/tv/1000_miles_f...</td>\n",
       "      <td>https://www.rottentomatoes.com/tv/1000_miles_f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.rottentomatoes.com/m/12_strong_2022</td>\n",
       "      <td>https://www.rottentomatoes.com/m/12_strong</td>\n",
       "      <td>https://www.rottentomatoes.com/tv/12_strong_2022</td>\n",
       "      <td>https://www.rottentomatoes.com/tv/12_strong</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url  \\\n",
       "0           https://www.rottentomatoes.com/m/83_2022   \n",
       "1  https://www.rottentomatoes.com/m/10_days_of_a_...   \n",
       "2  https://www.rottentomatoes.com/m/10_days_of_a_...   \n",
       "3  https://www.rottentomatoes.com/m/1000_miles_fr...   \n",
       "4    https://www.rottentomatoes.com/m/12_strong_2022   \n",
       "\n",
       "                                                url2  \\\n",
       "0                https://www.rottentomatoes.com/m/83   \n",
       "1  https://www.rottentomatoes.com/m/10_days_of_a_...   \n",
       "2  https://www.rottentomatoes.com/m/10_days_of_a_...   \n",
       "3  https://www.rottentomatoes.com/m/1000_miles_fr...   \n",
       "4         https://www.rottentomatoes.com/m/12_strong   \n",
       "\n",
       "                                                url3  \\\n",
       "0          https://www.rottentomatoes.com/tv/83_2022   \n",
       "1  https://www.rottentomatoes.com/tv/10_days_of_a...   \n",
       "2  https://www.rottentomatoes.com/tv/10_days_of_a...   \n",
       "3  https://www.rottentomatoes.com/tv/1000_miles_f...   \n",
       "4   https://www.rottentomatoes.com/tv/12_strong_2022   \n",
       "\n",
       "                                                url4  \n",
       "0               https://www.rottentomatoes.com/tv/83  \n",
       "1  https://www.rottentomatoes.com/tv/10_days_of_a...  \n",
       "2  https://www.rottentomatoes.com/tv/10_days_of_a...  \n",
       "3  https://www.rottentomatoes.com/tv/1000_miles_f...  \n",
       "4        https://www.rottentomatoes.com/tv/12_strong  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url_df = na_genre[['url','url2','url3','url4']]\n",
    "url_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['need to check!!', 'need to check!!']\n"
     ]
    }
   ],
   "source": [
    "scrapped_name, scrapped_cat = wc.automate_data_collection(url_df.to_numpy(), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NA', 'NA']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scrapped_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting into 5 subsets to do the scraping in parts \n",
    "num_rows_per_part = len(url_df) // 5\n",
    "url_df_parts = np.array_split(url_df, 5)\n",
    "part1 = url_df_parts[0]\n",
    "part2 = url_df_parts[1]\n",
    "part3 = url_df_parts[2]\n",
    "part4 = url_df_parts[3]\n",
    "part5 = url_df_parts[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creates a dataframe with genre, show_title, and audience scores for titles with Na values for genre\n",
    "def makedf(scrapped_name):\n",
    "    movie_data = []\n",
    "    i=0\n",
    "    for entry in scrapped_name:\n",
    "        if entry!= 'NA':\n",
    "            title, details = entry.split('\\n', 1)\n",
    "            info, tomato_meter, _,_, audience_score, _, _ = details.split('\\n')\n",
    "            comma1=info.find(',')\n",
    "            comma2=info.rfind(',')\n",
    "            genre=info[comma1+2:comma2]\n",
    "            movie_data.append([title, genre, tomato_meter, audience_score])\n",
    "    df = pd.DataFrame(movie_data, columns=['show_title', 'genre', 'tomatometer', 'audience_score'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#part 1: Status: Not scraped\n",
    "scrapped_name1, scrapped_cat1 = wc.automate_data_collection(part1.to_numpy(), len(part1))\n",
    "part1df=makedf(scrapped_name1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#part 2: Status: Not scraped\n",
    "scrapped_name2, scrapped_cat2 = wc.automate_data_collection(part2.to_numpy(), len(part2))\n",
    "part2df=makedf(scrapped_name2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IS TV!\n",
      "Documentary,Crime;umentary,CrimeOriginalLanguageEnglish(UnitedKingdom)ReleaseDateApr6,2022\n",
      "IS TV!\n",
      "Adventure,Action,Fantasy,Anime;enture,Action,Fantasy,AnimeOriginalLanguageJapaneseReleaseDateOct6,2012\n",
      "IS TV!\n",
      "Action,Horror,Anime;ion,Horror,AnimeOriginalLanguageJapaneseReleaseDateOct3,2020\n",
      "IS TV!\n",
      "Kids&Family,Action,Adventure,Animation;s&Family,Action,Adventure,AnimationOriginalLanguageEnglishReleaseDateSep18,2020\n",
      "IS TV!\n",
      "Drama;maOriginalLanguageKoreanReleaseDateFeb25,2022\n",
      "IS TV!\n",
      "Action,Anime;ion,AnimeOriginalLanguageJapaneseReleaseDateJul31,2019\n",
      "IS TV!\n",
      "Drama,Mystery&Thriller;ma,Mystery&ThrillerOriginalLanguageHindiReleaseDateOct18,2023\n",
      "IS TV!\n",
      "Crime,Drama,Mystery&Thriller;me,Drama,Mystery&ThrillerOriginalLanguageEnglishReleaseDateJan1,2023\n",
      "IS TV!\n",
      "Mystery&Thriller,Sci-Fi,Drama;tery&Thriller,Sci-Fi,DramaOriginalLanguageIcelandicReleaseDateJun17,2021\n",
      "IS TV!\n",
      "Drama;maOriginalLanguageEnglishReleaseDateJul28,2022\n",
      "IS TV!\n",
      "Documentary,Crime;umentary,CrimeOriginalLanguageEnglishReleaseDateJun8,2022\n",
      "IS TV!\n",
      "Crime,Drama,Action;me,Drama,ActionOriginalLanguageHindiReleaseDateNov25,2022\n"
     ]
    },
    {
     "ename": "WebDriverException",
     "evalue": "Message: disconnected: not connected to DevTools\n  (failed to check if window was closed: disconnected: not connected to DevTools)\n  (Session info: chrome=124.0.6367.61)\nStacktrace:\n0   chromedriver                        0x0000000101206934 chromedriver + 4368692\n1   chromedriver                        0x00000001011fedc8 chromedriver + 4337096\n2   chromedriver                        0x0000000100e22c04 chromedriver + 289796\n3   chromedriver                        0x0000000100e0bd00 chromedriver + 195840\n4   chromedriver                        0x0000000100e0bc3c chromedriver + 195644\n5   chromedriver                        0x0000000100e9cd24 chromedriver + 789796\n6   chromedriver                        0x0000000100e59ab4 chromedriver + 514740\n7   chromedriver                        0x0000000100e5a50c chromedriver + 517388\n8   chromedriver                        0x00000001011cae50 chromedriver + 4124240\n9   chromedriver                        0x00000001011cfc40 chromedriver + 4144192\n10  chromedriver                        0x00000001011b0818 chromedriver + 4016152\n11  chromedriver                        0x00000001011d0570 chromedriver + 4146544\n12  chromedriver                        0x00000001011a22cc chromedriver + 3957452\n13  chromedriver                        0x00000001011efeb8 chromedriver + 4275896\n14  chromedriver                        0x00000001011f0034 chromedriver + 4276276\n15  chromedriver                        0x00000001011fea28 chromedriver + 4336168\n16  libsystem_pthread.dylib             0x000000019f22af94 _pthread_start + 136\n17  libsystem_pthread.dylib             0x000000019f225d34 thread_start + 8\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNoSuchElementException\u001b[0m                    Traceback (most recent call last)",
      "File \u001b[0;32m~/Desktop/ORIE4741FinalProject/scraping/web_crawler.py:63\u001b[0m, in \u001b[0;36mautomate_data_collection\u001b[0;34m(urls, n)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 63\u001b[0m   h1 \u001b[39m=\u001b[39m driver\u001b[39m.\u001b[39mfind_element(By\u001b[39m.\u001b[39mID, \u001b[39m'\u001b[39m\u001b[39mscoreboard\u001b[39m\u001b[39m'\u001b[39m) \u001b[39m#checks if the link is right \u001b[39;00m\n\u001b[1;32m     64\u001b[0m   \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mIS MOVIE\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m/Applications/anaconda3/lib/python3.11/site-packages/selenium/webdriver/remote/webdriver.py:741\u001b[0m, in \u001b[0;36mWebDriver.find_element\u001b[0;34m(self, by, value)\u001b[0m\n\u001b[1;32m    739\u001b[0m     value \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m[name=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mvalue\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m]\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m--> 741\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexecute(Command\u001b[39m.\u001b[39mFIND_ELEMENT, {\u001b[39m\"\u001b[39m\u001b[39musing\u001b[39m\u001b[39m\"\u001b[39m: by, \u001b[39m\"\u001b[39m\u001b[39mvalue\u001b[39m\u001b[39m\"\u001b[39m: value})[\u001b[39m\"\u001b[39m\u001b[39mvalue\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m/Applications/anaconda3/lib/python3.11/site-packages/selenium/webdriver/remote/webdriver.py:347\u001b[0m, in \u001b[0;36mWebDriver.execute\u001b[0;34m(self, driver_command, params)\u001b[0m\n\u001b[1;32m    346\u001b[0m \u001b[39mif\u001b[39;00m response:\n\u001b[0;32m--> 347\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39merror_handler\u001b[39m.\u001b[39mcheck_response(response)\n\u001b[1;32m    348\u001b[0m     response[\u001b[39m\"\u001b[39m\u001b[39mvalue\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_unwrap_value(response\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mvalue\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n",
      "File \u001b[0;32m/Applications/anaconda3/lib/python3.11/site-packages/selenium/webdriver/remote/errorhandler.py:229\u001b[0m, in \u001b[0;36mErrorHandler.check_response\u001b[0;34m(self, response)\u001b[0m\n\u001b[1;32m    228\u001b[0m     \u001b[39mraise\u001b[39;00m exception_class(message, screen, stacktrace, alert_text)  \u001b[39m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[39;00m\n\u001b[0;32m--> 229\u001b[0m \u001b[39mraise\u001b[39;00m exception_class(message, screen, stacktrace)\n",
      "\u001b[0;31mNoSuchElementException\u001b[0m: Message: no such element: Unable to locate element: {\"method\":\"css selector\",\"selector\":\"[id=\"scoreboard\"]\"}\n  (Session info: chrome=124.0.6367.61); For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors#no-such-element-exception\nStacktrace:\n0   chromedriver                        0x0000000101206934 chromedriver + 4368692\n1   chromedriver                        0x00000001011fedc8 chromedriver + 4337096\n2   chromedriver                        0x0000000100e22c04 chromedriver + 289796\n3   chromedriver                        0x0000000100e64e00 chromedriver + 560640\n4   chromedriver                        0x0000000100e9d5ec chromedriver + 792044\n5   chromedriver                        0x0000000100e59ab4 chromedriver + 514740\n6   chromedriver                        0x0000000100e5a50c chromedriver + 517388\n7   chromedriver                        0x00000001011cae50 chromedriver + 4124240\n8   chromedriver                        0x00000001011cfc40 chromedriver + 4144192\n9   chromedriver                        0x00000001011b0818 chromedriver + 4016152\n10  chromedriver                        0x00000001011d0570 chromedriver + 4146544\n11  chromedriver                        0x00000001011a22cc chromedriver + 3957452\n12  chromedriver                        0x00000001011efeb8 chromedriver + 4275896\n13  chromedriver                        0x00000001011f0034 chromedriver + 4276276\n14  chromedriver                        0x00000001011fea28 chromedriver + 4336168\n15  libsystem_pthread.dylib             0x000000019f22af94 _pthread_start + 136\n16  libsystem_pthread.dylib             0x000000019f225d34 thread_start + 8\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNoSuchElementException\u001b[0m                    Traceback (most recent call last)",
      "File \u001b[0;32m~/Desktop/ORIE4741FinalProject/scraping/web_crawler.py:86\u001b[0m, in \u001b[0;36mautomate_data_collection\u001b[0;34m(urls, n)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 86\u001b[0m   h1 \u001b[39m=\u001b[39m driver\u001b[39m.\u001b[39mfind_element(By\u001b[39m.\u001b[39mID, \u001b[39m'\u001b[39m\u001b[39mscoreboard\u001b[39m\u001b[39m'\u001b[39m) \u001b[39m#checks if the link is right \u001b[39;00m\n\u001b[1;32m     87\u001b[0m   \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mIS MOVIE\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m/Applications/anaconda3/lib/python3.11/site-packages/selenium/webdriver/remote/webdriver.py:741\u001b[0m, in \u001b[0;36mWebDriver.find_element\u001b[0;34m(self, by, value)\u001b[0m\n\u001b[1;32m    739\u001b[0m     value \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m[name=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mvalue\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m]\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m--> 741\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexecute(Command\u001b[39m.\u001b[39mFIND_ELEMENT, {\u001b[39m\"\u001b[39m\u001b[39musing\u001b[39m\u001b[39m\"\u001b[39m: by, \u001b[39m\"\u001b[39m\u001b[39mvalue\u001b[39m\u001b[39m\"\u001b[39m: value})[\u001b[39m\"\u001b[39m\u001b[39mvalue\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m/Applications/anaconda3/lib/python3.11/site-packages/selenium/webdriver/remote/webdriver.py:347\u001b[0m, in \u001b[0;36mWebDriver.execute\u001b[0;34m(self, driver_command, params)\u001b[0m\n\u001b[1;32m    346\u001b[0m \u001b[39mif\u001b[39;00m response:\n\u001b[0;32m--> 347\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39merror_handler\u001b[39m.\u001b[39mcheck_response(response)\n\u001b[1;32m    348\u001b[0m     response[\u001b[39m\"\u001b[39m\u001b[39mvalue\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_unwrap_value(response\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mvalue\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n",
      "File \u001b[0;32m/Applications/anaconda3/lib/python3.11/site-packages/selenium/webdriver/remote/errorhandler.py:229\u001b[0m, in \u001b[0;36mErrorHandler.check_response\u001b[0;34m(self, response)\u001b[0m\n\u001b[1;32m    228\u001b[0m     \u001b[39mraise\u001b[39;00m exception_class(message, screen, stacktrace, alert_text)  \u001b[39m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[39;00m\n\u001b[0;32m--> 229\u001b[0m \u001b[39mraise\u001b[39;00m exception_class(message, screen, stacktrace)\n",
      "\u001b[0;31mNoSuchElementException\u001b[0m: Message: no such element: Unable to locate element: {\"method\":\"css selector\",\"selector\":\"[id=\"scoreboard\"]\"}\n  (Session info: chrome=124.0.6367.61); For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors#no-such-element-exception\nStacktrace:\n0   chromedriver                        0x0000000101206934 chromedriver + 4368692\n1   chromedriver                        0x00000001011fedc8 chromedriver + 4337096\n2   chromedriver                        0x0000000100e22c04 chromedriver + 289796\n3   chromedriver                        0x0000000100e64e00 chromedriver + 560640\n4   chromedriver                        0x0000000100e9d5ec chromedriver + 792044\n5   chromedriver                        0x0000000100e59ab4 chromedriver + 514740\n6   chromedriver                        0x0000000100e5a50c chromedriver + 517388\n7   chromedriver                        0x00000001011cae50 chromedriver + 4124240\n8   chromedriver                        0x00000001011cfc40 chromedriver + 4144192\n9   chromedriver                        0x00000001011b0818 chromedriver + 4016152\n10  chromedriver                        0x00000001011d0570 chromedriver + 4146544\n11  chromedriver                        0x00000001011a22cc chromedriver + 3957452\n12  chromedriver                        0x00000001011efeb8 chromedriver + 4275896\n13  chromedriver                        0x00000001011f0034 chromedriver + 4276276\n14  chromedriver                        0x00000001011fea28 chromedriver + 4336168\n15  libsystem_pthread.dylib             0x000000019f22af94 _pthread_start + 136\n16  libsystem_pthread.dylib             0x000000019f225d34 thread_start + 8\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mWebDriverException\u001b[0m                        Traceback (most recent call last)",
      "File \u001b[0;32m~/Desktop/ORIE4741FinalProject/scraping/web_crawler.py:103\u001b[0m, in \u001b[0;36mautomate_data_collection\u001b[0;34m(urls, n)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[39mif\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m/tv/\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m url):\n\u001b[0;32m--> 103\u001b[0m   h1 \u001b[39m=\u001b[39m driver\u001b[39m.\u001b[39mfind_element(By\u001b[39m.\u001b[39mCLASS_NAME, \u001b[39m\"\u001b[39m\u001b[39mmedia-info\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39m#checks if the link is right \u001b[39;00m\n\u001b[1;32m    104\u001b[0m   \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mIS TV!\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m/Applications/anaconda3/lib/python3.11/site-packages/selenium/webdriver/remote/webdriver.py:741\u001b[0m, in \u001b[0;36mWebDriver.find_element\u001b[0;34m(self, by, value)\u001b[0m\n\u001b[1;32m    739\u001b[0m     value \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m[name=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mvalue\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m]\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m--> 741\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexecute(Command\u001b[39m.\u001b[39mFIND_ELEMENT, {\u001b[39m\"\u001b[39m\u001b[39musing\u001b[39m\u001b[39m\"\u001b[39m: by, \u001b[39m\"\u001b[39m\u001b[39mvalue\u001b[39m\u001b[39m\"\u001b[39m: value})[\u001b[39m\"\u001b[39m\u001b[39mvalue\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m/Applications/anaconda3/lib/python3.11/site-packages/selenium/webdriver/remote/webdriver.py:347\u001b[0m, in \u001b[0;36mWebDriver.execute\u001b[0;34m(self, driver_command, params)\u001b[0m\n\u001b[1;32m    346\u001b[0m \u001b[39mif\u001b[39;00m response:\n\u001b[0;32m--> 347\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39merror_handler\u001b[39m.\u001b[39mcheck_response(response)\n\u001b[1;32m    348\u001b[0m     response[\u001b[39m\"\u001b[39m\u001b[39mvalue\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_unwrap_value(response\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mvalue\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n",
      "File \u001b[0;32m/Applications/anaconda3/lib/python3.11/site-packages/selenium/webdriver/remote/errorhandler.py:229\u001b[0m, in \u001b[0;36mErrorHandler.check_response\u001b[0;34m(self, response)\u001b[0m\n\u001b[1;32m    228\u001b[0m     \u001b[39mraise\u001b[39;00m exception_class(message, screen, stacktrace, alert_text)  \u001b[39m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[39;00m\n\u001b[0;32m--> 229\u001b[0m \u001b[39mraise\u001b[39;00m exception_class(message, screen, stacktrace)\n",
      "\u001b[0;31mWebDriverException\u001b[0m: Message: unknown error: cannot determine loading status\nfrom disconnected: unable to send message to renderer\n  (Session info: chrome=124.0.6367.61)\nStacktrace:\n0   chromedriver                        0x0000000101206934 chromedriver + 4368692\n1   chromedriver                        0x00000001011fedc8 chromedriver + 4337096\n2   chromedriver                        0x0000000100e22c04 chromedriver + 289796\n3   chromedriver                        0x0000000100e0c3c0 chromedriver + 197568\n4   chromedriver                        0x0000000100e0ab1c chromedriver + 191260\n5   chromedriver                        0x0000000100e0b7f0 chromedriver + 194544\n6   chromedriver                        0x0000000100e1a584 chromedriver + 255364\n7   chromedriver                        0x0000000100e9d470 chromedriver + 791664\n8   chromedriver                        0x0000000100e59ab4 chromedriver + 514740\n9   chromedriver                        0x0000000100e5a50c chromedriver + 517388\n10  chromedriver                        0x00000001011cae50 chromedriver + 4124240\n11  chromedriver                        0x00000001011cfc40 chromedriver + 4144192\n12  chromedriver                        0x00000001011b0818 chromedriver + 4016152\n13  chromedriver                        0x00000001011d0570 chromedriver + 4146544\n14  chromedriver                        0x00000001011a22cc chromedriver + 3957452\n15  chromedriver                        0x00000001011efeb8 chromedriver + 4275896\n16  chromedriver                        0x00000001011f0034 chromedriver + 4276276\n17  chromedriver                        0x00000001011fea28 chromedriver + 4336168\n18  libsystem_pthread.dylib             0x000000019f22af94 _pthread_start + 136\n19  libsystem_pthread.dylib             0x000000019f225d34 thread_start + 8\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mWebDriverException\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#part 3: Status: Not scraped\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m scrapped_name3, scrapped_cat3 \u001b[38;5;241m=\u001b[39m wc\u001b[38;5;241m.\u001b[39mautomate_data_collection(part3\u001b[38;5;241m.\u001b[39mto_numpy(), \u001b[38;5;28mlen\u001b[39m(part3))\n\u001b[1;32m      3\u001b[0m part3df\u001b[38;5;241m=\u001b[39mmakedf(scrapped_name3)\n",
      "File \u001b[0;32m~/Desktop/ORIE4741FinalProject/scraping/web_crawler.py:121\u001b[0m, in \u001b[0;36mautomate_data_collection\u001b[0;34m(urls, n)\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[39mexcept\u001b[39;00m: \u001b[39m#link 3 does not exist, we try link 4\u001b[39;00m\n\u001b[1;32m    120\u001b[0m   url \u001b[39m=\u001b[39m i[\u001b[39m3\u001b[39m]\n\u001b[0;32m--> 121\u001b[0m   driver\u001b[39m.\u001b[39mget(url)\n\u001b[1;32m    123\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[39mif\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m/tv/\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m url):\n",
      "File \u001b[0;32m/Applications/anaconda3/lib/python3.11/site-packages/selenium/webdriver/remote/webdriver.py:356\u001b[0m, in \u001b[0;36mWebDriver.get\u001b[0;34m(self, url)\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget\u001b[39m(\u001b[39mself\u001b[39m, url: \u001b[39mstr\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    355\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Loads a web page in the current browser session.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 356\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexecute(Command\u001b[39m.\u001b[39mGET, {\u001b[39m\"\u001b[39m\u001b[39murl\u001b[39m\u001b[39m\"\u001b[39m: url})\n",
      "File \u001b[0;32m/Applications/anaconda3/lib/python3.11/site-packages/selenium/webdriver/remote/webdriver.py:347\u001b[0m, in \u001b[0;36mWebDriver.execute\u001b[0;34m(self, driver_command, params)\u001b[0m\n\u001b[1;32m    345\u001b[0m response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcommand_executor\u001b[39m.\u001b[39mexecute(driver_command, params)\n\u001b[1;32m    346\u001b[0m \u001b[39mif\u001b[39;00m response:\n\u001b[0;32m--> 347\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39merror_handler\u001b[39m.\u001b[39mcheck_response(response)\n\u001b[1;32m    348\u001b[0m     response[\u001b[39m\"\u001b[39m\u001b[39mvalue\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_unwrap_value(response\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mvalue\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[1;32m    349\u001b[0m     \u001b[39mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m/Applications/anaconda3/lib/python3.11/site-packages/selenium/webdriver/remote/errorhandler.py:229\u001b[0m, in \u001b[0;36mErrorHandler.check_response\u001b[0;34m(self, response)\u001b[0m\n\u001b[1;32m    227\u001b[0m         alert_text \u001b[39m=\u001b[39m value[\u001b[39m\"\u001b[39m\u001b[39malert\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    228\u001b[0m     \u001b[39mraise\u001b[39;00m exception_class(message, screen, stacktrace, alert_text)  \u001b[39m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[39;00m\n\u001b[0;32m--> 229\u001b[0m \u001b[39mraise\u001b[39;00m exception_class(message, screen, stacktrace)\n",
      "\u001b[0;31mWebDriverException\u001b[0m: Message: disconnected: not connected to DevTools\n  (failed to check if window was closed: disconnected: not connected to DevTools)\n  (Session info: chrome=124.0.6367.61)\nStacktrace:\n0   chromedriver                        0x0000000101206934 chromedriver + 4368692\n1   chromedriver                        0x00000001011fedc8 chromedriver + 4337096\n2   chromedriver                        0x0000000100e22c04 chromedriver + 289796\n3   chromedriver                        0x0000000100e0bd00 chromedriver + 195840\n4   chromedriver                        0x0000000100e0bc3c chromedriver + 195644\n5   chromedriver                        0x0000000100e9cd24 chromedriver + 789796\n6   chromedriver                        0x0000000100e59ab4 chromedriver + 514740\n7   chromedriver                        0x0000000100e5a50c chromedriver + 517388\n8   chromedriver                        0x00000001011cae50 chromedriver + 4124240\n9   chromedriver                        0x00000001011cfc40 chromedriver + 4144192\n10  chromedriver                        0x00000001011b0818 chromedriver + 4016152\n11  chromedriver                        0x00000001011d0570 chromedriver + 4146544\n12  chromedriver                        0x00000001011a22cc chromedriver + 3957452\n13  chromedriver                        0x00000001011efeb8 chromedriver + 4275896\n14  chromedriver                        0x00000001011f0034 chromedriver + 4276276\n15  chromedriver                        0x00000001011fea28 chromedriver + 4336168\n16  libsystem_pthread.dylib             0x000000019f22af94 _pthread_start + 136\n17  libsystem_pthread.dylib             0x000000019f225d34 thread_start + 8\n"
     ]
    }
   ],
   "source": [
    "#part 3: Status: Not scraped\n",
    "scrapped_name3, scrapped_cat3 = wc.automate_data_collection(part3.to_numpy(), len(part3))\n",
    "part3df=makedf(scrapped_name3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#part 4: Status: Not scraped\n",
    "scrapped_name4, scrapped_cat4 = wc.automate_data_collection(part4.to_numpy(), len(part4))\n",
    "part4df=makedf(scrapped_name4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#part 5: Status: Not scraped\n",
    "scrapped_name5, scrapped_cat5 = wc.automate_data_collection(part5.to_numpy(), len(part5))\n",
    "part5df=makedf(scrapped_name5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = pd.concat([part1df, part2df, part3df, part4df, part5df])\n",
    "combined_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "df.to_csv('genreinfo.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "cd78fef2128015050713e82ca51c6520b11aee7c9ee8df750520bbbc7384cbaa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
