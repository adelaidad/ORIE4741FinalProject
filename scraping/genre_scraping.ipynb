{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MAIN_GENRE and Scraping\n",
    "We retrieve the genre information from the Rotten Tomatoes website since it is well-known and if frequently updated. Before scraping, we inspected the website using /robots.txt. We then proceeded scraping the information while complying with the instructions posted on the page.\n",
    "\n",
    "The code used to scrape can be found in web_crawler.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnhandled error. \n",
      "View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "pip install selenium\n",
    "pip install unidecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnhandled error. \n",
      "View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import SGDClassifier, LogisticRegression\n",
    "from sklearn.metrics import RocCurveDisplay, recall_score, precision_score, roc_curve, roc_auc_score, balanced_accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnhandled error. \n",
      "View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# import for scrapping\n",
    "from unidecode import unidecode\n",
    "import web_crawler as wc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnhandled error. \n",
      "View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "comb_df=pd.read_csv('comb_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnhandled error. \n",
      "View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "na_genre = comb_df[comb_df['MAIN_GENRE'].isna()]\n",
    "type(na_genre)\n",
    "g = na_genre.drop_duplicates(subset='show_title')\n",
    "type(g)\n",
    "len(g)\n",
    "g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnhandled error. \n",
      "View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "na_genre = comb_df[comb_df['MAIN_GENRE'].isna()]\n",
    "na_genre = na_genre.drop_duplicates(subset='show_title')\n",
    "\n",
    "na_genre_cols = ['category', 'show_title','week']\n",
    "na_genre = na_genre[na_genre_cols]\n",
    "print(\"shape of na_genre initially: \", na_genre.shape)\n",
    "\n",
    "def mapping_category(string):\n",
    "  ''' \n",
    "  Method to find the category which will later be used in url parsing \n",
    "  '''\n",
    "  string = unidecode(string)\n",
    "\n",
    "  if(string==\"Films (English)\"):\n",
    "    string = \"m\"\n",
    "  else:\n",
    "    string = \"tv\"\n",
    "  # print(string)\n",
    "  return string\n",
    "\n",
    "def mapping_title(name):\n",
    "  '''\n",
    "  Method to find the title name which will later be used in url parsing\n",
    "  '''\n",
    "  name = unidecode(name)\n",
    "  name = name.lower()\n",
    "  #removing all punctuation\n",
    "  # https://www.geeksforgeeks.org/python-remove-punctuation-from-string/\n",
    "  punctuation = '''!()-[]{};:'\"\\,<>./?@#$%^&*_~'''\n",
    "  for punctuation in punctuation:\n",
    "    name = name.replace(punctuation, '')\n",
    "  list = name.split()\n",
    "  return \"_\".join(list)\n",
    "\n",
    "def alt_mapping_category(string):\n",
    "  \"\"\"\n",
    "  Method to find the category which will later be used in url parsing just in case \n",
    "  given category was incorrectly listed \n",
    "  \"\"\"\n",
    "\n",
    "  #in case the type was incorrectly listed \n",
    "  string = unidecode(string)\n",
    "  if(string==\"m\"):\n",
    "    string = \"tv\"\n",
    "  else:\n",
    "    string = \"m\"\n",
    "  # print(string)\n",
    "  return string\n",
    "\n",
    "def mapping_year(week):\n",
    "  \"\"\"\n",
    "  Method to find the release year which will later be used in url parsing in the\n",
    "  case that shows have duplicate names \n",
    "  \"\"\"\n",
    "  return week[:4]\n",
    "\n",
    "na_genre['category'] = na_genre['category'].map(mapping_category)\n",
    "\n",
    "na_genre['show_title'] = na_genre['show_title'].map(mapping_title)\n",
    "\n",
    "na_genre['category2'] = na_genre['category'].map(alt_mapping_category)\n",
    "\n",
    "na_genre['year'] = na_genre['week'].map(mapping_year)\n",
    "\n",
    "na_genre[\"url\"] = \"https://www.rottentomatoes.com/\" + na_genre[\"category\"]+\"/\"+na_genre['show_title']+\"_\"+na_genre['year'] #first try\n",
    "\n",
    "na_genre[\"url2\"] = \"https://www.rottentomatoes.com/\" + na_genre[\"category\"]+\"/\"+na_genre['show_title'] #second try \n",
    "\n",
    "na_genre[\"url3\"] = \"https://www.rottentomatoes.com/\" + na_genre[\"category2\"]+\"/\"+na_genre['show_title']+\"_\"+na_genre['year'] #third try\n",
    "\n",
    "na_genre[\"url4\"] = \"https://www.rottentomatoes.com/\" + na_genre[\"category2\"]+\"/\"+na_genre['show_title'] #fourth try \n",
    "\n",
    "na_genre = na_genre.drop_duplicates(subset=['show_title'])\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "na_genre.to_csv(\"output_filename.csv\", index=False, encoding='utf8')\n",
    "\n",
    "# na_genre.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnhandled error. \n",
      "View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "na_genre.reset_index(drop=True)\n",
    "# import web_crawler as wc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnhandled error. \n",
      "View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "url_df = na_genre[['url','url2','url3','url4']]\n",
    "url_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnhandled error. \n",
      "View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "scrapped_name, scrapped_cat = wc.automate_data_collection(url_df.to_numpy(), 1768)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnhandled error. \n",
      "View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#Creates a dataframe with genre, show_title, and audience scores for titles with Na values for genre\n",
    "movie_data = []\n",
    "i=0\n",
    "for entry in scrapped_name:\n",
    "    if entry!= 'NA':\n",
    "        title, details = entry.split('\\n', 1)\n",
    "        info, tomato_meter, _,_, audience_score, _, _ = details.split('\\n')\n",
    "        comma1=info.find(',')\n",
    "        comma2=info.rfind(',')\n",
    "        genre=info[comma1+2:comma2]\n",
    "        movie_data.append([title, genre, tomato_meter, audience_score])\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(movie_data, columns=['show_title', 'genre', 'tomatometer', 'audience_score'])\n",
    "# df.to_csv('genreinfo.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cd78fef2128015050713e82ca51c6520b11aee7c9ee8df750520bbbc7384cbaa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
